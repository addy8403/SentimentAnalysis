{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T07:09:53.187690Z","iopub.execute_input":"2024-07-08T07:09:53.188368Z","iopub.status.idle":"2024-07-08T07:09:53.614725Z","shell.execute_reply.started":"2024-07-08T07:09:53.188320Z","shell.execute_reply":"2024-07-08T07:09:53.613580Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:09:56.597676Z","iopub.execute_input":"2024-07-08T07:09:56.598542Z","iopub.status.idle":"2024-07-08T07:09:56.602839Z","shell.execute_reply.started":"2024-07-08T07:09:56.598507Z","shell.execute_reply":"2024-07-08T07:09:56.601767Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/input/imdb-dataset/IMDB Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:09:59.135241Z","iopub.execute_input":"2024-07-08T07:09:59.136238Z","iopub.status.idle":"2024-07-08T07:09:59.824609Z","shell.execute_reply.started":"2024-07-08T07:09:59.136202Z","shell.execute_reply":"2024-07-08T07:09:59.823378Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=df.sample(24000)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:10:00.831621Z","iopub.execute_input":"2024-07-08T07:10:00.832002Z","iopub.status.idle":"2024-07-08T07:10:00.846892Z","shell.execute_reply.started":"2024-07-08T07:10:00.831972Z","shell.execute_reply":"2024-07-08T07:10:00.845957Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:09:58.778170Z","iopub.execute_input":"2024-07-08T14:09:58.779066Z","iopub.status.idle":"2024-07-08T14:09:58.794751Z","shell.execute_reply.started":"2024-07-08T14:09:58.779030Z","shell.execute_reply":"2024-07-08T14:09:58.793682Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment  \\\n7469   This is the weakest of the series, not much of...  negative   \n7859   Fantastic movie! One of the best film noir mov...  positive   \n37418  This film is so bad and gets worse in every im...  negative   \n32221  What gives Anthony Minghella the right to ruin...  negative   \n46753  OK, please believe me when I say that this is ...  negative   \n\n                                        tokenized_review  \n7469   [this, is, the, weakest, of, the, series, ,, n...  \n7859   [fantastic, movie, !, one, of, the, best, film...  \n37418  [this, film, is, so, bad, and, gets, worse, in...  \n32221  [what, gives, anthony, minghella, the, right, ...  \n46753  [ok, ,, please, believe, me, when, i, say, tha...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>tokenized_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7469</th>\n      <td>This is the weakest of the series, not much of...</td>\n      <td>negative</td>\n      <td>[this, is, the, weakest, of, the, series, ,, n...</td>\n    </tr>\n    <tr>\n      <th>7859</th>\n      <td>Fantastic movie! One of the best film noir mov...</td>\n      <td>positive</td>\n      <td>[fantastic, movie, !, one, of, the, best, film...</td>\n    </tr>\n    <tr>\n      <th>37418</th>\n      <td>This film is so bad and gets worse in every im...</td>\n      <td>negative</td>\n      <td>[this, film, is, so, bad, and, gets, worse, in...</td>\n    </tr>\n    <tr>\n      <th>32221</th>\n      <td>What gives Anthony Minghella the right to ruin...</td>\n      <td>negative</td>\n      <td>[what, gives, anthony, minghella, the, right, ...</td>\n    </tr>\n    <tr>\n      <th>46753</th>\n      <td>OK, please believe me when I say that this is ...</td>\n      <td>negative</td>\n      <td>[ok, ,, please, believe, me, when, i, say, tha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df=df.drop('tokenized_review')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:09:38.166384Z","iopub.execute_input":"2024-07-08T14:09:38.167080Z","iopub.status.idle":"2024-07-08T14:09:40.610067Z","shell.execute_reply.started":"2024-07-08T14:09:38.167045Z","shell.execute_reply":"2024-07-08T14:09:40.608544Z"},"trusted":true},"execution_count":23,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenized_review\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n","\u001b[0;31mKeyError\u001b[0m: \"['tokenized_review'] not found in axis\""],"ename":"KeyError","evalue":"\"['tokenized_review'] not found in axis\"","output_type":"error"}]},{"cell_type":"code","source":"df.to_csv('/kaggle/working/my_dataframe.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:10:30.976977Z","iopub.execute_input":"2024-07-08T14:10:30.977412Z","iopub.status.idle":"2024-07-08T14:10:35.197583Z","shell.execute_reply.started":"2024-07-08T14:10:30.977378Z","shell.execute_reply":"2024-07-08T14:10:35.196774Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom torch.optim import AdamW\n!pip install pytorch-lightning\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch.utils.data import DataLoader,TensorDataset\nimport pytorch_lightning as L\nfrom torch.nn.utils.rnn import pad_sequence\nimport smart_open.local_file\nfrom gensim.models import Word2Vec\n\n\nimport gensim.downloader as api","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:10:09.743132Z","iopub.execute_input":"2024-07-08T07:10:09.743923Z","iopub.status.idle":"2024-07-08T07:10:40.905722Z","shell.execute_reply.started":"2024-07-08T07:10:09.743885Z","shell.execute_reply":"2024-07-08T07:10:40.904752Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.2.5)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.26.4)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.1.2)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.4)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.3.1)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.4.0.post0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.9.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.11.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"import gensim.downloader as api","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loading GloVe embeddings...\")\nglove_vectors = api.load(\"glove-wiki-gigaword-300\")\nprint(\"GloVe embeddings loaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:10:40.907480Z","iopub.execute_input":"2024-07-08T07:10:40.908074Z","iopub.status.idle":"2024-07-08T07:12:44.562182Z","shell.execute_reply.started":"2024-07-08T07:10:40.908040Z","shell.execute_reply":"2024-07-08T07:12:44.561072Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loading GloVe embeddings...\nGloVe embeddings loaded.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import threading\n\nstop_execution = threading.Event()\n\ndef long_running_task():\n    while not stop_execution.is_set():\n        # Your code here\n        print(\"Loading GloVe embeddings...\")\n        glove_vectors = api.load(\"glove-wiki-gigaword-300\")\n        print(\"GloVe embeddings loaded.\")\n        if stop_execution.is_set():\n            print(\"Execution stopped\")\n            break\n\nthreading.Thread(target=long_running_task).start()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_execution.set()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def safe_tokenize(text):\n    if isinstance(text, str):\n        return word_tokenize(text.lower())\n    else:\n        return []\n\n# Assuming df is your DataFrame with 'review' and 'sentiment' columns\ndf['tokenized_review'] = df['review'].fillna('').apply(safe_tokenize)\ndf = df[df['tokenized_review'].map(len) > 0]\n\nvector_size = 300\nmax_seq_length = 200\n\ndef review_to_vector_sequence(review, embeddings, max_length):\n    vectors = [embeddings[word] for word in review[:max_length] if word in embeddings]\n    if len(vectors) == 0:\n        return [np.zeros(vector_size)]\n    return vectors\n\n# Convert reviews to sequences of vectors using GloVe\nprint(\"Converting reviews to vector sequences...\")\nreview_vector_sequences = df['tokenized_review'].apply(lambda x: review_to_vector_sequence(x, glove_vectors, max_seq_length))\n\ndef pad_vectors(vectors, max_length, padding_value=0):\n    array = np.array(vectors)\n    padded = np.zeros((max_length, vector_size), dtype=np.float32)\n    length = min(array.shape[0], max_length)\n    padded[:length, :] = array[:length, :]\n    return torch.from_numpy(padded)\n\n# Convert reviews to padded tensors\nprint(\"Creating padded tensors...\")\nX = pad_sequence([pad_vectors(seq, max_seq_length) for seq in review_vector_sequences], batch_first=True)\ny = torch.tensor(df['sentiment'].map({'positive': 1, 'negative': 0}).values, dtype=torch.float32)\n\n# Create tensor datasets\ndataset = TensorDataset(X, y)\n\nprint(\"Data preparation complete. You can now use this dataset in your RNN model.\")\nprint(f\"Input shape: {X.shape}\")  # Should be (num_samples, max_seq_length, vector_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:12:44.563686Z","iopub.execute_input":"2024-07-08T07:12:44.564032Z","iopub.status.idle":"2024-07-08T07:14:17.692493Z","shell.execute_reply.started":"2024-07-08T07:12:44.564004Z","shell.execute_reply":"2024-07-08T07:14:17.691437Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Converting reviews to vector sequences...\nCreating padded tensors...\nData preparation complete. You can now use this dataset in your RNN model.\nInput shape: torch.Size([24000, 200, 300])\n","output_type":"stream"}]},{"cell_type":"code","source":"class RNN(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        \n        self.w1 = nn.Parameter(torch.Tensor(300, 64), requires_grad=True)\n        self.w2 = nn.Parameter(torch.Tensor(64, 64), requires_grad=True)\n        self.w3 = nn.Parameter(torch.Tensor(64, 1), requires_grad=True)\n        self.bh = nn.Parameter(torch.Tensor(1, 64), requires_grad=True)\n        self.bo = nn.Parameter(torch.Tensor(1, 1), requires_grad=True)\n        self.init_weights()\n\n    def init_weights(self):\n        for param in [self.w1, self.w2, self.w3]:\n            nn.init.xavier_uniform_(param)\n        nn.init.zeros_(self.bh)\n        nn.init.zeros_(self.bo)\n\n    def rnn_math(self, input, o_t):\n        o_t = torch.tanh(torch.matmul(input, self.w1) + torch.matmul(o_t, self.w2) + self.bh)\n        return o_t\n\n    def forward(self, input):\n        batch_size, seq_len, _ = input.shape\n        o_t = torch.zeros(batch_size, 64, device=self.device)\n        for i in range(seq_len):\n            o_t = self.rnn_math(input[:,i, :], o_t)\n        return torch.sigmoid(torch.matmul(o_t, self.w3) + self.bo)\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), lr=1e-3)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000, eta_min=1e-6)\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": scheduler,\n            \"monitor\": \"train_loss\"\n        }\n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = nn.functional.binary_cross_entropy_with_logits(outputs, labels.unsqueeze(1).float())\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n        return loss\n    def validation_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = nn.functional.binary_cross_entropy_with_logits(outputs, labels.unsqueeze(1).float())\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:14:17.695393Z","iopub.execute_input":"2024-07-08T07:14:17.695859Z","iopub.status.idle":"2024-07-08T07:14:17.712520Z","shell.execute_reply.started":"2024-07-08T07:14:17.695812Z","shell.execute_reply":"2024-07-08T07:14:17.711409Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntotal_size = len(dataset)\ntrain_size = int(0.8 * total_size)  # 80% for training\nval_size = total_size - train_size  # 20% for validation\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ndef create_dataloader(dataset, batch_size, shuffle=True):\n    return DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=4,\n        pin_memory=True,\n        persistent_workers=True,\n        prefetch_factor=2,\n    )\nbatch_size = 8096 \ndataloader = create_dataloader(dataset, batch_size)\nval_dataloader = create_dataloader(val_dataset, batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:14:17.713677Z","iopub.execute_input":"2024-07-08T07:14:17.713943Z","iopub.status.idle":"2024-07-08T07:14:17.735670Z","shell.execute_reply.started":"2024-07-08T07:14:17.713920Z","shell.execute_reply":"2024-07-08T07:14:17.731695Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model=RNN()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:14:17.736850Z","iopub.execute_input":"2024-07-08T07:14:17.737216Z","iopub.status.idle":"2024-07-08T07:14:17.744885Z","shell.execute_reply.started":"2024-07-08T07:14:17.737179Z","shell.execute_reply":"2024-07-08T07:14:17.743859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class GPUUsageCallback(L.Callback):\n    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n        if batch_idx % 100 == 0:  # Print every 100 batches\n            for i in range(torch.cuda.device_count()):\n                print(f\"GPU {i} memory usage: {torch.cuda.memory_allocated(i) / 1e9:.2f} GB\")\n\ntrainer = L.Trainer(\n    max_epochs=10,\n    accelerator=\"gpu\",\n    devices=2,  # Use both T4 GPUs\n    strategy=\"ddp_notebook\",  # Distributed Data Parallel\n    precision='16-mixed',\n    gradient_clip_val=1.0,\n    accumulate_grad_batches=2,\n    )\ntrainer.fit(model, train_dataloaders=dataloader, val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:15:07.900285Z","iopub.execute_input":"2024-07-08T07:15:07.901812Z","iopub.status.idle":"2024-07-08T07:16:14.854002Z","shell.execute_reply.started":"2024-07-08T07:15:07.901758Z","shell.execute_reply":"2024-07-08T07:16:14.852910Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-07-08 07:15:11.127840: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 07:15:11.127905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 07:15:11.129898: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"617c126abc3d4178b1bac890ab28378c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"import joblib\njoblib.dump(model, 'my_model.joblib2')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:11:29.286951Z","iopub.execute_input":"2024-07-08T14:11:29.287379Z","iopub.status.idle":"2024-07-08T14:11:29.299381Z","shell.execute_reply.started":"2024-07-08T14:11:29.287327Z","shell.execute_reply":"2024-07-08T14:11:29.298286Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['my_model.joblib2']"},"metadata":{}}]},{"cell_type":"code","source":"\nmodel = joblib.load('/kaggle/input/model2/my_model.joblib2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(trainer.checkpoint_callback.best_model_path,'chkpt2')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:11:52.047309Z","iopub.execute_input":"2024-07-08T14:11:52.048008Z","iopub.status.idle":"2024-07-08T14:11:52.054973Z","shell.execute_reply.started":"2024-07-08T14:11:52.047973Z","shell.execute_reply":"2024-07-08T14:11:52.053816Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['chkpt2']"},"metadata":{}}]},{"cell_type":"code","source":"\nk = joblib.load('/kaggle/working/lightning_logs/version_8/checkpoints/epoch=4049-step=12130.ckpt', encoding='latin1')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:20:46.113163Z","iopub.execute_input":"2024-07-08T14:20:46.113591Z","iopub.status.idle":"2024-07-08T14:20:46.165091Z","shell.execute_reply.started":"2024-07-08T14:20:46.113557Z","shell.execute_reply":"2024-07-08T14:20:46.163698Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/lightning_logs/version_8/checkpoints/epoch=4049-step=12130.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'encoding'"],"ename":"TypeError","evalue":"load() got an unexpected keyword argument 'encoding'","output_type":"error"}]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/lightning_logs/version_8/checkpoints/epoch=4049-step=12130.ckpt')\nprint(checkpoint.keys())","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:22:13.278158Z","iopub.execute_input":"2024-07-08T14:22:13.278940Z","iopub.status.idle":"2024-07-08T14:22:13.289686Z","shell.execute_reply.started":"2024-07-08T14:22:13.278904Z","shell.execute_reply":"2024-07-08T14:22:13.288601Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(checkpoint, '/kaggle/working/saved_checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:24:04.192483Z","iopub.execute_input":"2024-07-08T14:24:04.193227Z","iopub.status.idle":"2024-07-08T14:24:04.200872Z","shell.execute_reply.started":"2024-07-08T14:24:04.193188Z","shell.execute_reply":"2024-07-08T14:24:04.199890Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_state.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:19:13.912716Z","iopub.execute_input":"2024-07-08T14:19:13.913116Z","iopub.status.idle":"2024-07-08T14:19:13.920307Z","shell.execute_reply.started":"2024-07-08T14:19:13.913086Z","shell.execute_reply":"2024-07-08T14:19:13.919399Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"k=joblib.load('/kaggle/working/lightning_logs/version_8/checkpoints/epoch=4049-step=12130.ckpt')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:16:14.060333Z","iopub.execute_input":"2024-07-08T14:16:14.061225Z","iopub.status.idle":"2024-07-08T14:16:14.426164Z","shell.execute_reply.started":"2024-07-08T14:16:14.061183Z","shell.execute_reply":"2024-07-08T14:16:14.424598Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/pickle.py:1245\u001b[0m, in \u001b[0;36m_Unpickler.load_persid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1245\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x80 in position 63: ordinal not in range(128)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k\u001b[38;5;241m=\u001b[39m\u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/lightning_logs/version_8/checkpoints/epoch=4049-step=12130.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n","File \u001b[0;32m/opt/conda/lib/python3.10/pickle.py:1247\u001b[0m, in \u001b[0;36m_Unpickler.load_persid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersistent IDs in protocol 0 must be ASCII strings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_load(pid))\n","\u001b[0;31mUnpicklingError\u001b[0m: persistent IDs in protocol 0 must be ASCII strings"],"ename":"UnpicklingError","evalue":"persistent IDs in protocol 0 must be ASCII strings","output_type":"error"}]},{"cell_type":"code","source":"path = joblib.load('/kaggle/input/chkpt2/chkpt2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_better_checkpoint=trainer.checkpoint_callback.best_model_path\ntrainer=L.Trainer(max_epochs=100)\ntrainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_better_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:16:21.652602Z","iopub.execute_input":"2024-07-08T07:16:21.653022Z","iopub.status.idle":"2024-07-08T07:25:03.236880Z","shell.execute_reply.started":"2024-07-08T07:16:21.652981Z","shell.execute_reply":"2024-07-08T07:25:03.235825Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n2024-07-08 07:16:22.255847: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 07:16:22.255929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 07:16:22.257456: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:361: The dirpath has changed from '/kaggle/working/lightning_logs/version_4/checkpoints' to '/kaggle/working/lightning_logs/version_5/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b23f39f946ba4ca088774a8a9a0f4804"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(100):\n    print(f\"Review {i+1}: Label->{y[i]}  and predicted value:\",model.forward((X[i:i+1]).clone().detach()))\n\n\nloss=nn.functional.binary_cross_entropy_with_logits(model.forward(X[:20000]),y[:20000].unsqueeze(1))\n\nprint(loss.item())","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:29:03.022901Z","iopub.execute_input":"2024-07-08T10:29:03.023291Z","iopub.status.idle":"2024-07-08T10:29:06.883256Z","shell.execute_reply.started":"2024-07-08T10:29:03.023261Z","shell.execute_reply":"2024-07-08T10:29:06.882255Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Review 1: Label->0.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 2: Label->1.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 3: Label->0.0  and predicted value: tensor([[0.0003]], grad_fn=<SigmoidBackward0>)\nReview 4: Label->0.0  and predicted value: tensor([[0.0025]], grad_fn=<SigmoidBackward0>)\nReview 5: Label->0.0  and predicted value: tensor([[0.0087]], grad_fn=<SigmoidBackward0>)\nReview 6: Label->1.0  and predicted value: tensor([[0.0183]], grad_fn=<SigmoidBackward0>)\nReview 7: Label->1.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 8: Label->1.0  and predicted value: tensor([[0.0326]], grad_fn=<SigmoidBackward0>)\nReview 9: Label->0.0  and predicted value: tensor([[0.0049]], grad_fn=<SigmoidBackward0>)\nReview 10: Label->0.0  and predicted value: tensor([[0.6519]], grad_fn=<SigmoidBackward0>)\nReview 11: Label->1.0  and predicted value: tensor([[0.1369]], grad_fn=<SigmoidBackward0>)\nReview 12: Label->1.0  and predicted value: tensor([[0.0002]], grad_fn=<SigmoidBackward0>)\nReview 13: Label->0.0  and predicted value: tensor([[0.0049]], grad_fn=<SigmoidBackward0>)\nReview 14: Label->1.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 15: Label->0.0  and predicted value: tensor([[0.0115]], grad_fn=<SigmoidBackward0>)\nReview 16: Label->0.0  and predicted value: tensor([[0.0049]], grad_fn=<SigmoidBackward0>)\nReview 17: Label->0.0  and predicted value: tensor([[8.1608e-05]], grad_fn=<SigmoidBackward0>)\nReview 18: Label->1.0  and predicted value: tensor([[0.8833]], grad_fn=<SigmoidBackward0>)\nReview 19: Label->1.0  and predicted value: tensor([[0.0055]], grad_fn=<SigmoidBackward0>)\nReview 20: Label->1.0  and predicted value: tensor([[0.0226]], grad_fn=<SigmoidBackward0>)\nReview 21: Label->0.0  and predicted value: tensor([[0.0019]], grad_fn=<SigmoidBackward0>)\nReview 22: Label->1.0  and predicted value: tensor([[0.0051]], grad_fn=<SigmoidBackward0>)\nReview 23: Label->0.0  and predicted value: tensor([[0.0060]], grad_fn=<SigmoidBackward0>)\nReview 24: Label->1.0  and predicted value: tensor([[0.0049]], grad_fn=<SigmoidBackward0>)\nReview 25: Label->1.0  and predicted value: tensor([[0.0031]], grad_fn=<SigmoidBackward0>)\nReview 26: Label->1.0  and predicted value: tensor([[0.0052]], grad_fn=<SigmoidBackward0>)\nReview 27: Label->0.0  and predicted value: tensor([[0.0086]], grad_fn=<SigmoidBackward0>)\nReview 28: Label->1.0  and predicted value: tensor([[0.0003]], grad_fn=<SigmoidBackward0>)\nReview 29: Label->1.0  and predicted value: tensor([[0.4219]], grad_fn=<SigmoidBackward0>)\nReview 30: Label->1.0  and predicted value: tensor([[0.0050]], grad_fn=<SigmoidBackward0>)\nReview 31: Label->0.0  and predicted value: tensor([[0.0020]], grad_fn=<SigmoidBackward0>)\nReview 32: Label->0.0  and predicted value: tensor([[0.0025]], grad_fn=<SigmoidBackward0>)\nReview 33: Label->0.0  and predicted value: tensor([[0.0112]], grad_fn=<SigmoidBackward0>)\nReview 34: Label->1.0  and predicted value: tensor([[0.0046]], grad_fn=<SigmoidBackward0>)\nReview 35: Label->0.0  and predicted value: tensor([[0.0059]], grad_fn=<SigmoidBackward0>)\nReview 36: Label->0.0  and predicted value: tensor([[0.0022]], grad_fn=<SigmoidBackward0>)\nReview 37: Label->0.0  and predicted value: tensor([[0.0011]], grad_fn=<SigmoidBackward0>)\nReview 38: Label->1.0  and predicted value: tensor([[0.0024]], grad_fn=<SigmoidBackward0>)\nReview 39: Label->1.0  and predicted value: tensor([[0.0074]], grad_fn=<SigmoidBackward0>)\nReview 40: Label->0.0  and predicted value: tensor([[0.0052]], grad_fn=<SigmoidBackward0>)\nReview 41: Label->1.0  and predicted value: tensor([[0.0043]], grad_fn=<SigmoidBackward0>)\nReview 42: Label->1.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 43: Label->0.0  and predicted value: tensor([[0.0061]], grad_fn=<SigmoidBackward0>)\nReview 44: Label->1.0  and predicted value: tensor([[0.0061]], grad_fn=<SigmoidBackward0>)\nReview 45: Label->0.0  and predicted value: tensor([[0.8905]], grad_fn=<SigmoidBackward0>)\nReview 46: Label->0.0  and predicted value: tensor([[0.0059]], grad_fn=<SigmoidBackward0>)\nReview 47: Label->0.0  and predicted value: tensor([[0.0051]], grad_fn=<SigmoidBackward0>)\nReview 48: Label->1.0  and predicted value: tensor([[0.0123]], grad_fn=<SigmoidBackward0>)\nReview 49: Label->1.0  and predicted value: tensor([[0.0038]], grad_fn=<SigmoidBackward0>)\nReview 50: Label->1.0  and predicted value: tensor([[0.0006]], grad_fn=<SigmoidBackward0>)\nReview 51: Label->1.0  and predicted value: tensor([[0.0047]], grad_fn=<SigmoidBackward0>)\nReview 52: Label->0.0  and predicted value: tensor([[0.0019]], grad_fn=<SigmoidBackward0>)\nReview 53: Label->1.0  and predicted value: tensor([[0.3451]], grad_fn=<SigmoidBackward0>)\nReview 54: Label->1.0  and predicted value: tensor([[0.0288]], grad_fn=<SigmoidBackward0>)\nReview 55: Label->0.0  and predicted value: tensor([[0.0021]], grad_fn=<SigmoidBackward0>)\nReview 56: Label->1.0  and predicted value: tensor([[0.0003]], grad_fn=<SigmoidBackward0>)\nReview 57: Label->1.0  and predicted value: tensor([[0.0794]], grad_fn=<SigmoidBackward0>)\nReview 58: Label->1.0  and predicted value: tensor([[0.0010]], grad_fn=<SigmoidBackward0>)\nReview 59: Label->0.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 60: Label->1.0  and predicted value: tensor([[0.0070]], grad_fn=<SigmoidBackward0>)\nReview 61: Label->1.0  and predicted value: tensor([[0.0004]], grad_fn=<SigmoidBackward0>)\nReview 62: Label->0.0  and predicted value: tensor([[0.0075]], grad_fn=<SigmoidBackward0>)\nReview 63: Label->1.0  and predicted value: tensor([[0.0051]], grad_fn=<SigmoidBackward0>)\nReview 64: Label->0.0  and predicted value: tensor([[0.0007]], grad_fn=<SigmoidBackward0>)\nReview 65: Label->1.0  and predicted value: tensor([[0.8584]], grad_fn=<SigmoidBackward0>)\nReview 66: Label->1.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 67: Label->0.0  and predicted value: tensor([[0.0052]], grad_fn=<SigmoidBackward0>)\nReview 68: Label->0.0  and predicted value: tensor([[0.0052]], grad_fn=<SigmoidBackward0>)\nReview 69: Label->1.0  and predicted value: tensor([[0.0587]], grad_fn=<SigmoidBackward0>)\nReview 70: Label->1.0  and predicted value: tensor([[0.0056]], grad_fn=<SigmoidBackward0>)\nReview 71: Label->0.0  and predicted value: tensor([[0.0004]], grad_fn=<SigmoidBackward0>)\nReview 72: Label->1.0  and predicted value: tensor([[0.0052]], grad_fn=<SigmoidBackward0>)\nReview 73: Label->0.0  and predicted value: tensor([[0.0175]], grad_fn=<SigmoidBackward0>)\nReview 74: Label->1.0  and predicted value: tensor([[0.0016]], grad_fn=<SigmoidBackward0>)\nReview 75: Label->0.0  and predicted value: tensor([[0.0008]], grad_fn=<SigmoidBackward0>)\nReview 76: Label->1.0  and predicted value: tensor([[0.0147]], grad_fn=<SigmoidBackward0>)\nReview 77: Label->1.0  and predicted value: tensor([[0.0051]], grad_fn=<SigmoidBackward0>)\nReview 78: Label->0.0  and predicted value: tensor([[0.0005]], grad_fn=<SigmoidBackward0>)\nReview 79: Label->1.0  and predicted value: tensor([[0.0008]], grad_fn=<SigmoidBackward0>)\nReview 80: Label->1.0  and predicted value: tensor([[0.0368]], grad_fn=<SigmoidBackward0>)\nReview 81: Label->1.0  and predicted value: tensor([[0.0127]], grad_fn=<SigmoidBackward0>)\nReview 82: Label->0.0  and predicted value: tensor([[0.0083]], grad_fn=<SigmoidBackward0>)\nReview 83: Label->0.0  and predicted value: tensor([[0.0049]], grad_fn=<SigmoidBackward0>)\nReview 84: Label->1.0  and predicted value: tensor([[0.0156]], grad_fn=<SigmoidBackward0>)\nReview 85: Label->0.0  and predicted value: tensor([[0.0070]], grad_fn=<SigmoidBackward0>)\nReview 86: Label->1.0  and predicted value: tensor([[0.0008]], grad_fn=<SigmoidBackward0>)\nReview 87: Label->0.0  and predicted value: tensor([[0.0020]], grad_fn=<SigmoidBackward0>)\nReview 88: Label->1.0  and predicted value: tensor([[0.0115]], grad_fn=<SigmoidBackward0>)\nReview 89: Label->1.0  and predicted value: tensor([[0.0167]], grad_fn=<SigmoidBackward0>)\nReview 90: Label->1.0  and predicted value: tensor([[0.1780]], grad_fn=<SigmoidBackward0>)\nReview 91: Label->1.0  and predicted value: tensor([[0.0107]], grad_fn=<SigmoidBackward0>)\nReview 92: Label->0.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 93: Label->0.0  and predicted value: tensor([[0.0035]], grad_fn=<SigmoidBackward0>)\nReview 94: Label->1.0  and predicted value: tensor([[0.0089]], grad_fn=<SigmoidBackward0>)\nReview 95: Label->0.0  and predicted value: tensor([[0.0002]], grad_fn=<SigmoidBackward0>)\nReview 96: Label->0.0  and predicted value: tensor([[0.0053]], grad_fn=<SigmoidBackward0>)\nReview 97: Label->1.0  and predicted value: tensor([[0.0004]], grad_fn=<SigmoidBackward0>)\nReview 98: Label->1.0  and predicted value: tensor([[0.0061]], grad_fn=<SigmoidBackward0>)\nReview 99: Label->1.0  and predicted value: tensor([[0.0003]], grad_fn=<SigmoidBackward0>)\nReview 100: Label->1.0  and predicted value: tensor([[0.0506]], grad_fn=<SigmoidBackward0>)\n0.6863350868225098\n","output_type":"stream"}]},{"cell_type":"code","source":"path_to_better_checkpoint=trainer.checkpoint_callback.best_model_path\ntrainer=L.Trainer(max_epochs=2000)\ntrainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_better_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:25:03.238932Z","iopub.execute_input":"2024-07-08T07:25:03.239283Z","iopub.status.idle":"2024-07-08T10:26:34.421435Z","shell.execute_reply.started":"2024-07-08T07:25:03.239248Z","shell.execute_reply":"2024-07-08T10:26:34.420588Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:361: The dirpath has changed from '/kaggle/working/lightning_logs/version_5/checkpoints' to '/kaggle/working/lightning_logs/version_6/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e18368f2a5364cacae0a96c47573ba73"}},"metadata":{}}]},{"cell_type":"code","source":"path_to_better_checkpoint=trainer.checkpoint_callback.best_model_path\ntrainer=L.Trainer(max_epochs=4050)\ntrainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_better_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:59:30.435756Z","iopub.execute_input":"2024-07-08T13:59:30.436567Z","iopub.status.idle":"2024-07-08T14:04:19.213769Z","shell.execute_reply.started":"2024-07-08T13:59:30.436521Z","shell.execute_reply":"2024-07-08T14:04:19.210188Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:361: The dirpath has changed from '/kaggle/working/lightning_logs/version_7/checkpoints' to '/kaggle/working/lightning_logs/version_8/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100e319f06f845e1a605ef30a41b7dc4"}},"metadata":{}}]},{"cell_type":"code","source":"for i in range(100):\n    print(f\"Review {i+1}: Label->{y[i]}  and predicted value:\",model.forward((X[i:i+1]).clone().detach()))\n\n\nloss=nn.functional.binary_cross_entropy_with_logits(model.forward(X[:20000]),y[:20000].unsqueeze(1))\n\nprint(loss.item())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():  # Disable gradient calculation\n    output = model.forward(X[:24000])\n\nfor i in range(24000):\n    if(output[i,0]>=0.5):\n        output[i,0]=1\n    else:\n        output[i,0]=0\ni=0\naccuracy = accuracy_score(output,y[:24000].unsqueeze(1))\nprecision = precision_score(output,y[:24000].unsqueeze(1))\nrecall= recall_score(output,y[:24000].unsqueeze(1))\nfl= f1_score(output,y[:24000].unsqueeze(1))\n\nprint(accuracy)\nprint(precision)\nprint(recall)\nprint(fl)\n\ni=i+1\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T14:04:25.463794Z","iopub.execute_input":"2024-07-08T14:04:25.464618Z","iopub.status.idle":"2024-07-08T14:04:28.068300Z","shell.execute_reply.started":"2024-07-08T14:04:25.464577Z","shell.execute_reply":"2024-07-08T14:04:28.067312Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"0.58025\n0.20804922667553633\n0.8197903014416776\n0.3318742538798249\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"RNN()"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.move( '/kaggle/output/output_file.csv','/kaggle/working/lightning_logs',)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.move('/kaggle/output/output_file.csv','/kaggle/input/imdb-dataset/output1.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\n\ndef save_best_model_path(trainer):\n    best_model_path = trainer.checkpoint_callback.best_model_path\n    \n    # Create a dictionary with the information\n    info = {\n        \"best_model_path\": best_model_path,\n        \"current_epoch\": trainer.current_epoch,\n        \"global_step\": trainer.global_step\n    }\n    \n    # Save the information to a JSON file\n    with open('/kaggle/working/best_model_info.json', 'w') as f:\n        json.dump(info, f)\n\n    print(f\"Best model path saved: {best_model_path}\")\n\nsave_best_model_path(trainer)\n\ndef load_best_model_path():\n    try:\n        with open('/kaggle/working/best_model_info.json', 'r') as f:\n            info = json.load(f)\n        return info['best_model_path']\n    except FileNotFoundError:\n        print(\"No saved best model path found.\")\n        return None\n\n# Load the best model path\nbest_model_path = load_best_model_path()\n\nif best_model_path:\n    print(f\"Loading model from: {best_model_path}\")\n    model = RNN.load_from_checkpoint(best_model_path)\n\npath_to_better_checkpoint=best_model_path\ntrainer=L.Trainer(max_epochs=3002)\n\ntrainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_better_checkpoint)\n\n1000 epochs: \n0.6741309762001038,\n0.58135\n0.2209431485408462\n0.7687983134223472\n0.34324260726331474\n3000 epochs:\n0.615\n0.7259\n0.470766434413814\n0.9508464205588415\n0.6297446980953668\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\ndef tensor_3d_to_dataframe(tensor):\n    # Ensure the tensor is on CPU and convert to numpy\n    if tensor.is_cuda:\n        tensor = tensor.cpu()\n    \n    # Convert to numpy array\n    array_3d = tensor.numpy()\n    \n    # Get the dimensions\n    samples, seq_length, features = array_3d.shape\n    \n    # Reshape the 3D array to 2D\n    array_2d = array_3d.reshape(samples, seq_length * features)\n    \n    # Create column names\n    column_names = [f'feature_{i}_{j}' for i in range(seq_length) for j in range(features)]\n    \n    # Create DataFrame\n    df = pd.DataFrame(array_2d, columns=column_names)\n    \n    return df\n\ndf= tensor_3d_to_dataframe(X)\n\nprint(df.shape)\nprint(df.head())\n\ny = y.cpu().numpy()  # Assuming y is your labels tensor\ndf['label'] = y\n\n\n\nimport pandas as pd\nimport os\nfrom datetime import datetime\n\ndef save_dataframe(df, base_filename, folder='/kaggle/working/'):\n    # Create a timestamp\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    # Create the full filename with timestamp\n    filename = f\"{base_filename}_{timestamp}.csv\"\n    \n    # Create the full path\n    full_path = os.path.join(folder, filename)\n    \n    # Save the DataFrame to CSV\n    df.to_csv(full_path, index=False)\n    \n    print(f\"DataFrame saved to {full_path}\")\n    \n    # Optionally, you can also save a small metadata file with the latest filename\n    metadata = {'latest_file': filename}\n    pd.DataFrame(metadata, index=[0]).to_csv(os.path.join(folder, f\"{base_filename}_metadata.csv\"), index=False)\n\nsave_dataframe(df, 'my_dataframe')\n\ndef load_latest_dataframe(base_filename, folder='/kaggle/working/'):\n    metadata_file = os.path.join(folder, f\"{base_filename}_metadata.csv\")\n    \n    if os.path.exists(metadata_file):\n        metadata = pd.read_csv(metadata_file)\n        latest_file = metadata['latest_file'].iloc[0]\n        full_path = os.path.join(folder, latest_file)\n        \n        if os.path.exists(full_path):\n            df = pd.read_csv(full_path)\n            print(f\"Loaded DataFrame from {full_path}\")\n            return df\n        else:\n            print(f\"Latest file {full_path} not found.\")\n    else:\n        print(f\"No metadata file found at {metadata_file}\")\n    \n    return None\n\n# Load the latest DataFrame\ndf = load_latest_dataframe('my_dataframe')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}